{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.11"
    },
    "colab": {
      "name": "Colab Data Loading Example.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cylyu/ist718-project/blob/main/Colab_Data_Loading_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2MFoOG_Ew5U"
      },
      "source": [
        "# Example Project Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHlrBJe_Ew5V"
      },
      "source": [
        "There are only 2 accepted ways to load data for your project, from a cloud service or Google drive.  If you load data from a cloud service like github, you don't have to follow this format. Keep in mind that the graders do not expect to have to perform any manual steps to load your data from a cloud service.  If we don't see these cells at the start of your notebook, we will assume you are loading your data from a cloud service.<br>\n",
        "If you are loading data through Google drive, the following cells must be at the start of your notebook.  The naming scheme that we are requiring teams to use will allow us to run your code without having to modify your code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz4_z9V6Ew5V"
      },
      "source": [
        "# The first code cell of your notebook shall include all needed imports to run your project code.  Note that\n",
        "# there can be markdown cells above this cell.\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xvvG57CEw5V"
      },
      "source": [
        "# All data files shall be located in the following directory on \n",
        "# your google drive: /content/drive/My Drive/ist718_data/data_groupN\n",
        "\n",
        "# The following provides 2 example file names and their full path names.  This example assumes the assigned\n",
        "# group name is group12.  The definitions in this cell must be used to load all data files.\n",
        "# This is only an example, change these definitions to match your file names.\n",
        "car_data_csv = '/content/drive/My Drive/ist718_data/data_group12/car_data.csv'\n",
        "engine_data_csv = '/content/drive/My Drive/ist718_data/data_group12/engine_data.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXtjaLE4Ew5V"
      },
      "source": [
        "# The third code cell of your notebook must contain code to mount your google drive and load the data files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# You must use the definitions above to load your data.\n",
        "car_df = pd.read_csv(car_data_csv)\n",
        "engine_df = pd.read_csv(engine_data_csv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so2BLZ8AEw5V"
      },
      "source": [
        "# Other code or markdown cells follow ...\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jw2Bm0_NQyMy",
        "outputId": "9f95d071-3359-4932-83f6-c9902ceb0de0"
      },
      "source": [
        "%%bash\n",
        "pip install pyspark\n",
        "# Download tweets.csv from github\n",
        "# If the tweets.csv file does not exist in the colab environment\n",
        "if [[ ! -f ./nyc-rolling-sales.csv ]]; then \n",
        "   # download tweets.csv file from github and save it in this colab environment instance\n",
        "   wget https://github.com/cylyu/ist718-project/blob/main/nyc-rolling-sales.csv   \n",
        "fi\n",
        "\n",
        "# vefify tweets.csv exits in the colab env - should not print an error message\n",
        "ls nyc-rolling-sales.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading https://files.pythonhosted.org/packages/f0/26/198fc8c0b98580f617cb03cb298c6056587b8f0447e20fa40c5b634ced77/pyspark-3.0.1.tar.gz (204.2MB)\n",
            "Collecting py4j==0.10.9\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py): started\n",
            "  Building wheel for pyspark (setup.py): finished with status 'done'\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.1-py2.py3-none-any.whl size=204612243 sha256=fd22a863e6412a7ca85684dab8831d094c6964576a974f8e3b2087a137ab74d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/bd/07/031766ca628adec8435bb40f0bd83bb676ce65ff4007f8e73f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.1\n",
            "nyc-rolling-sales.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYjqnfoeTO-1"
      },
      "source": [
        "from pyspark.ml import feature\n",
        "from pyspark.ml import clustering\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import functions as fn\n",
        "from pyspark.sql import types\n",
        "from pyspark.sql.functions import from_utc_timestamp\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.sql.functions import col,lower\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import feature, regression, evaluation, Pipeline\n",
        "from pyspark.sql import functions as fn, Row\n",
        "import matplotlib.pyplot as plt\n",
        "from pyspark.ml.feature import StandardScaler,PCA\n",
        "from pyspark.sql.functions import concat, concat_ws\n",
        "import pandas as pd\n",
        "from pyspark.sql.types import DoubleType,IntegerType,TimestampType,DateType, StringType\n",
        "spark = SparkSession.builder.master(\"local[*]\").config(\"spark.memory.fraction\", 0.8).config(\"spark.executor.memory\", \"12g\").config(\"spark.driver.memory\", \"12g\").config(\"spark.memory.offHeap.enabled\",'true').config(\"spark.memory.offHeap.size\",\"12g\").getOrCreate()\n",
        "sparkContext=spark.sparkContext\n",
        "from pyspark.sql.functions import year, month, dayofmonth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dnr-wSJSljy"
      },
      "source": [
        "nyc_rolling_sales_df = spark.read.csv(\"nyc-rolling-sales.csv\", header=True, inferSchema=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnP5ijvzTCRI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}